import openai
import os
from datetime import datetime
import json
import sqlite3
from dotenv import load_dotenv
import re
from collections import Counter

load_dotenv()

class OpenAIIntegration:
    def __init__(self, db_path='ad_script_database.db'):
        self.db_path = db_path
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.client = None
        self.init_openai()
    
    def init_openai(self):
        """OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        if not self.api_key:
            print("âŒ OpenAI API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        try:
            self.client = openai.OpenAI(api_key=self.api_key)
            print("âœ… OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒæ­£å¸¸ã«åˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ")
            return True
        except Exception as e:
            print(f"âŒ OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return False
    
    def get_learning_data(self, category_id, platform):
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆå¼·åŒ–å­¦ç¿’æ©Ÿèƒ½ï¼‰"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å–å¾—
            cursor.execute('''
                SELECT pattern_type, pattern_content, effectiveness_score, frequency_count
                FROM learning_patterns
                WHERE category_id = ? AND platform = ? AND effectiveness_score > 0
                ORDER BY effectiveness_score DESC, frequency_count DESC
                LIMIT 20
            ''', (category_id, platform))
            
            positive_patterns = cursor.fetchall()
            
            # æ‚ªã„çµæœã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚‚å–å¾—
            cursor.execute('''
                SELECT pattern_type, pattern_content, effectiveness_score, frequency_count
                FROM learning_patterns
                WHERE category_id = ? AND platform = ? AND effectiveness_score < 0
                ORDER BY effectiveness_score ASC
                LIMIT 10
            ''', (category_id, platform))
            
            negative_patterns = cursor.fetchall()
            
            return {
                'positive_patterns': positive_patterns,
                'negative_patterns': negative_patterns
            }
        
        except Exception as e:
            print(f"âŒ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return {'positive_patterns': [], 'negative_patterns': []}
        
        finally:
            conn.close()
    
    def analyze_effective_scripts(self, reference_scripts):
        """åŠ¹æœçš„å°æœ¬ã‚’åˆ†æã—ã¦å…±é€šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º"""
        if not reference_scripts:
            return {}
        
        analysis = {
            'numerical_patterns': [],
            'authority_patterns': [],
            'urgency_patterns': [],
            'hook_starters': [],
            'cta_patterns': [],
            'frequent_keywords': [],
            'benefit_patterns': []
        }
        
        all_hooks = []
        all_mains = []
        all_ctas = []
        
        for script in reference_scripts:
            if len(script) > 3 and script[3]:
                all_hooks.append(script[3])
            if len(script) > 4 and script[4]:
                all_mains.append(script[4])
            if len(script) > 5 and script[5]:
                all_ctas.append(script[5])
        
        all_text = ' '.join(all_hooks + all_mains + all_ctas)
        
        # æ•°å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æŠ½å‡º
        numbers = re.findall(r'\d+[,\d]*[å††ï¼…%ä¸‡å„„åƒç™¾å]', all_text)
        analysis['numerical_patterns'] = list(set(numbers))
        
        # æ¨©å¨æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æŠ½å‡º
        authority_keywords = ['ãƒ—ãƒ­ãƒ‡ãƒ¥ãƒ¼ã‚¹', 'ãƒãƒ¼ãƒãƒ¼ãƒ‰', 'å¤§å­¦', 'ç ”ç©¶', 'åšå£«', 'åŒ»å¸«', 'å°‚é–€å®¶', 'èªå®š', 'æ‰¿èª', 'ç‰¹è¨±']
        for keyword in authority_keywords:
            if keyword in all_text:
                analysis['authority_patterns'].append(keyword)
        
        # ç·Šæ€¥æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æŠ½å‡º
        urgency_keywords = ['ä»Šãªã‚‰', 'é™å®š', 'ä»Šã ã‘', 'æœŸé–“é™å®š', 'æ•°é‡é™å®š', 'ä»Šã™ã', '1åº¦ã—ã‹', 'æ®‹ã‚Š', 'æœ€å¾Œ']
        for keyword in urgency_keywords:
            if keyword in all_text:
                analysis['urgency_patterns'].append(keyword)
        
        # ãƒ•ãƒƒã‚¯é–‹å§‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æŠ½å‡º
        hook_starters = []
        for hook in all_hooks:
            starter = hook[:10] if len(hook) > 10 else hook
            hook_starters.append(starter)
        analysis['hook_starters'] = hook_starters
        
        # CTAãƒ‘ã‚¿ãƒ¼ãƒ³ã®æŠ½å‡º
        cta_patterns = []
        for cta in all_ctas:
            if 'ãƒã‚§ãƒƒã‚¯' in cta:
                cta_patterns.append('ãƒã‚§ãƒƒã‚¯')
            if 'è©¦ã—ã¦' in cta:
                cta_patterns.append('è©¦ã—ã¦')
            if 'ç„¡æ–™' in cta:
                cta_patterns.append('ç„¡æ–™')
        analysis['cta_patterns'] = list(set(cta_patterns))
        
        # é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æŠ½å‡º
        words = re.findall(r'[ä¸€-é¾¯ã-ã‚”ã‚¡-ãƒ´ãƒ¼]+', all_text)
        word_counts = Counter(words)
        analysis['frequent_keywords'] = [word for word, count in word_counts.most_common(15) 
                                       if len(word) > 1 and count > 1]
        
        return analysis
    
    def create_integrated_prompt(self, category, target_audience, platform, 
                               script_length, reference_scripts=None, category_id=None):
        """çµ±åˆç‰ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆï¼ˆåŠ¹æœçš„å°æœ¬ + å¼·åŒ–å­¦ç¿’ã€ãƒˆãƒ¼ãƒ³å‰Šé™¤ï¼‰"""
        
        # 1. åŠ¹æœçš„å°æœ¬ã®åˆ†æï¼ˆ40%ã®é‡ã¿ï¼‰
        manual_analysis = self.analyze_effective_scripts(reference_scripts)
        
        # 2. å¼·åŒ–å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ï¼ˆ60%ã®é‡ã¿ï¼‰
        learning_data = self.get_learning_data(category_id, platform) if category_id else {'positive_patterns': [], 'negative_patterns': []}
        
        # å‚è€ƒå°æœ¬ã®è©³ç´°
        reference_details = ""
        if reference_scripts:
            reference_details = "\n\nã€åŠ¹æœçš„å°æœ¬ï¼ˆå°‚é–€å®¶é¸å®šï¼‰- é‡ã¿40%ã€‘\n"
            for i, script in enumerate(reference_scripts[:2], 1):
                script_title = script[2] if len(script) > 2 else "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜"
                script_hook = script[3] if len(script) > 3 else ""
                script_main = script[4] if len(script) > 4 else ""
                script_cta = script[5] if len(script) > 5 else ""
                script_reason = script[8] if len(script) > 8 else ""
                
                reference_details += f"""
åŠ¹æœçš„å°æœ¬{i}: {script_title}
ãƒ•ãƒƒã‚¯: {script_hook}
ãƒ¡ã‚¤ãƒ³: {script_main}
CTA: {script_cta}
åŠ¹æœçš„ãªç†ç”±: {script_reason}
"""
        
        # å¼·åŒ–å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æŒ‡ç¤º
        learning_instructions = ""
        if learning_data['positive_patterns']:
            learning_instructions += "\n\nã€å¼·åŒ–å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆé…ä¿¡çµæœåˆ†æï¼‰- é‡ã¿60%ã€‘\n"
            learning_instructions += "ğŸ¯ å®Ÿéš›ã®é…ä¿¡çµæœã§åŠ¹æœãŒç¢ºèªã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå¿…ãšæ´»ç”¨ï¼‰:\n"
            
            for pattern_type, content, score, count in learning_data['positive_patterns'][:10]:
                learning_instructions += f"- {pattern_type}: {content} (åŠ¹æœã‚¹ã‚³ã‚¢: {score:.2f}, å‡ºç¾å›æ•°: {count})\n"
        
        if learning_data['negative_patterns']:
            learning_instructions += "\nâš ï¸ é…ä¿¡çµæœã§åŠ¹æœãŒä½ã‹ã£ãŸãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆé¿ã‘ã¦ãã ã•ã„ï¼‰:\n"
            for pattern_type, content, score, count in learning_data['negative_patterns'][:5]:
                learning_instructions += f"- {pattern_type}: {content} (åŠ¹æœã‚¹ã‚³ã‚¢: {score:.2f})\n"
        
        # æ‰‹å‹•åˆ†æã®æŒ‡ç¤º
        manual_instructions = ""
        if manual_analysis:
            manual_instructions = f"""
ã€åŠ¹æœçš„å°æœ¬ã®åˆ†æçµæœã€‘
ğŸ”¢ æ•°å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³: {', '.join(manual_analysis['numerical_patterns'][:5])}
ğŸ† æ¨©å¨æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³: {', '.join(manual_analysis['authority_patterns'][:3])}
âš¡ ç·Šæ€¥æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³: {', '.join(manual_analysis['urgency_patterns'][:3])}
ğŸ¯ é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(manual_analysis['frequent_keywords'][:8])}
"""
        
        prompt = f"""
ã‚ãªãŸã¯{category}ã®åºƒå‘Šå°æœ¬ã‚’ä½œæˆã™ã‚‹è¶…ä¸€æµã®ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
åŠ¹æœçš„å°æœ¬ã®å°‚é–€å®¶åˆ†æã¨å®Ÿéš›ã®é…ä¿¡çµæœãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¦ã€æœ€é«˜å“è³ªã®å°æœ¬ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€åŸºæœ¬æ¡ä»¶ã€‘
- å•†æã‚«ãƒ†ã‚´ãƒªãƒ¼: {category}
- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤: {target_audience}
- ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ : {platform}
- å°æœ¬ã®é•·ã•: {script_length}

{reference_details}

{learning_instructions}

{manual_instructions}

ã€çµ±åˆä½œæˆæŒ‡ç¤ºã€‘
1. å¼·åŒ–å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆ60%é‡ã¿ï¼‰ã‚’æœ€å„ªå…ˆã§æ´»ç”¨
   - å®Ÿéš›ã®é…ä¿¡çµæœã§åŠ¹æœãŒç¢ºèªã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å¿…ãšå«ã‚ã‚‹
   - åŠ¹æœãŒä½ã‹ã£ãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã¯çµ¶å¯¾ã«é¿ã‘ã‚‹

2. åŠ¹æœçš„å°æœ¬ã®åˆ†æçµæœï¼ˆ40%é‡ã¿ï¼‰ã‚‚æ´»ç”¨
   - å°‚é–€å®¶ãŒé¸å®šã—ãŸæˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‚è€ƒã«ã™ã‚‹
   - å…·ä½“çš„ãªæ•°å­—ã€æ¨©å¨æ€§ã€ç·Šæ€¥æ€§ã‚’å«ã‚ã‚‹

3. ä¸¡æ–¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¦æœ€é©åŒ–
   - å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®é«˜ã‚¹ã‚³ã‚¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åŠ¹æœçš„å°æœ¬ã®æˆåŠŸè¦ç´ ã¨çµ„ã¿åˆã‚ã›ã‚‹
   - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã«æœ€ã‚‚éŸ¿ãçµ„ã¿åˆã‚ã›ã‚’é¸æŠ

ã€å¿…é ˆè¦ç´ ã€‘
âœ… å®Ÿéš›ã®é…ä¿¡çµæœã§åŠ¹æœãŒç¢ºèªã•ã‚ŒãŸè¦ç´ 
âœ… å…·ä½“çš„ãªæ•°å­—ï¼ˆä¾¡æ ¼ã€åŠ¹æœã€æœŸé–“ï¼‰
âœ… æ¨©å¨æ€§ã‚’ç¤ºã™è¦ç´ 
âœ… ç·Šæ€¥æ€§ã‚’æ¼”å‡ºã™ã‚‹è¦ç´ 
âœ… ãƒªã‚¹ã‚¯å›é¿è¦ç´ 

ã€å°æœ¬æ§‹æˆã®è©³ç´°è¦æ±‚ã€‘
âœ… ãƒ•ãƒƒã‚¯: 
- å…·ä½“çš„ãªæ•°å­—ã§å§‹ã‚ã‚‹
- æ¨©å¨æ€§ã‚„è©±é¡Œæ€§ã‚’å«ã‚ã‚‹
- 3-5ç§’ã§æ³¨æ„ã‚’å¼•ãå¼·åŠ›ãªè¨´æ±‚

âœ… ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„:
- å•†å“ã®å…·ä½“çš„ãªåŠ¹æœãƒ»ç‰¹å¾´
- æ•°å€¤ã«ã‚ˆã‚‹è£ä»˜ã‘
- æ¨©å¨æ€§ã®è¨¼æ˜
- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆ

âœ… CTA:
- ç·Šæ€¥æ€§ã®ã‚ã‚‹è¡Œå‹•å–šèµ·
- å…·ä½“çš„ãªç‰¹å…¸ã‚„å‰²å¼•
- ãƒªã‚¹ã‚¯å›é¿è¦ç´ 
- è¡Œå‹•ã‚’ä¿ƒã™æ˜ç¢ºãªæŒ‡ç¤º

ã€å‡ºåŠ›å½¢å¼ã€‘
ä»¥ä¸‹ã®JSONå½¢å¼ã§ã€ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ–ãƒ³ãªæœ€é©å°æœ¬ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

{{
    "title": "çµ±åˆåˆ†æã«åŸºã¥ãæœ€é©å°æœ¬ã‚¿ã‚¤ãƒˆãƒ«",
    "hook": "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ + åŠ¹æœçš„å°æœ¬ã®çµ±åˆãƒ•ãƒƒã‚¯",
    "main_content": "é…ä¿¡çµæœã§å®Ÿè¨¼ã•ã‚ŒãŸåŠ¹æœçš„ãªãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„",
    "call_to_action": "é«˜ã„ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå®Ÿè¨¼ã•ã‚ŒãŸCTA",
    "script_content": "å®Œå…¨ãªçµ±åˆå°æœ¬ãƒ†ã‚­ã‚¹ãƒˆ"
}}

é‡è¦: é…ä¿¡çµæœã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’60%ã€åŠ¹æœçš„å°æœ¬ã®åˆ†æã‚’40%ã®é‡ã¿ã§çµ±åˆã—ã€å®Ÿéš›ã®æˆæœã«åŸºã¥ã„ãŸå°æœ¬ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
        
        return prompt
    
    def generate_script(self, category, target_audience, platform, script_length, reference_scripts=None, category_id=None):
        """
        çµ±åˆç‰ˆå°æœ¬ç”Ÿæˆï¼ˆåŠ¹æœçš„å°æœ¬ + å¼·åŒ–å­¦ç¿’ã€ãƒˆãƒ¼ãƒ³å‰Šé™¤ã€NGãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯ï¼‰
        è¦ä»¶1å¯¾å¿œï¼šè‡ªå‹•ç”Ÿæˆå°æœ¬ã®ã¿NGãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯é©ç”¨
        """
        if not self.client:
            raise Exception("OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        try:
            # çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
            prompt = self.create_integrated_prompt(
                category, target_audience, platform, 
                script_length, reference_scripts, category_id
            )
            
            # è¦ä»¶1å¯¾å¿œï¼šè‡ªå‹•ç”Ÿæˆå°æœ¬ã«ã®ã¿NGãƒ¯ãƒ¼ãƒ‰æŒ‡ç¤ºã‚’è¿½åŠ 
            ng_words_instruction = ""
            if category_id:
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                cursor.execute('SELECT word, reason FROM ng_words WHERE category_id = ?', (category_id,))
                ng_words = cursor.fetchall()
                conn.close()
                
                if ng_words:
                    ng_words_instruction = f"""
                    
ã€é‡è¦ï¼šãƒ¬ã‚®ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆä½¿ç”¨ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ï¼‰ã€‘
ä»¥ä¸‹ã®è¨€è‘‰ã¯æ³•çš„ãƒ»ãƒ¬ã‚®ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸Šã®ç†ç”±ã«ã‚ˆã‚Šä½¿ç”¨ã‚’ç¦æ­¢ã•ã‚Œã¦ã„ã¾ã™ã€‚
å°æœ¬ä½œæˆæ™‚ã¯çµ¶å¯¾ã«ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ï¼š

ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰:
{chr(10).join([f"- {word} {f'ï¼ˆç†ç”±ï¼š{reason}ï¼‰' if reason else ''}" for word, reason in ng_words])}

ã“ã‚Œã‚‰ã®è¨€è‘‰ã‚’ä½¿ç”¨ã›ãšã«ã€åŠ¹æœçš„ã§é­…åŠ›çš„ãªå°æœ¬ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«NGãƒ¯ãƒ¼ãƒ‰æŒ‡ç¤ºã‚’è¿½åŠ 
            prompt += ng_words_instruction
            
            # OpenAI APIã§å°æœ¬ç”Ÿæˆ
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯åŠ¹æœçš„ãªåºƒå‘Šå°æœ¬ä½œæˆã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¬ã‚®ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éµå®ˆã‚’æœ€å„ªå…ˆã«ã€å®Ÿéš›ã®é…ä¿¡çµæœãƒ‡ãƒ¼ã‚¿ã¨å°‚é–€å®¶ã®åˆ†æã‚’çµ±åˆã—ã¦ã€æœ€é«˜å“è³ªã®å°æœ¬ã‚’ä½œæˆã™ã‚‹ã“ã¨ãŒå¾—æ„ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ–ãƒ³ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€å®Ÿè¨¼ã•ã‚ŒãŸæˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ´»ç”¨ã—ã¦ãã ã•ã„ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1200
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ
            response_text = response.choices[0].message.content
            
            # JSONã®æŠ½å‡ºã¨è§£æ
            try:
                start_idx = response_text.find('{')
                end_idx = response_text.rfind('}') + 1
                
                if start_idx != -1 and end_idx != -1:
                    json_str = response_text[start_idx:end_idx]
                    script_data = json.loads(json_str)
                else:
                    raise json.JSONDecodeError("JSONå½¢å¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", response_text, 0)
                
            except json.JSONDecodeError:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
                script_data = {
                    "title": f"{category}ã®çµ±åˆåˆ†æå°æœ¬",
                    "hook": "åŠ¹æœå®Ÿè¨¼æ¸ˆã¿ã®å¼·åŠ›ãªãƒ•ãƒƒã‚¯",
                    "main_content": "é…ä¿¡çµæœã¨ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆåˆ†æã‚’çµ±åˆã—ãŸãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„",
                    "call_to_action": "é«˜ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå®Ÿè¨¼ã•ã‚ŒãŸCTA",
                    "script_content": response_text
                }
            
            # å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç¢ºèª
            required_fields = ['title', 'hook', 'main_content', 'call_to_action']
            for field in required_fields:
                if field not in script_data:
                    script_data[field] = f"çµ±åˆåˆ†æã«ã‚ˆã‚‹{field}"
            
            # script_contentã®ä½œæˆ
            if not script_data.get('script_content'):
                script_data['script_content'] = f"""ğŸ£ ãƒ•ãƒƒã‚¯: {script_data['hook']}

ğŸ’¬ ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„: {script_data['main_content']}

ğŸ“¢ CTA: {script_data['call_to_action']}"""
            
            # è¦ä»¶1å¯¾å¿œï¼šè‡ªå‹•ç”Ÿæˆå°æœ¬ã®ã¿NGãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯ãƒ»ã‚¯ãƒªãƒ¼ãƒ³
            if category_id:
                cleaned_script, violations = self.check_and_clean_script(script_data, category_id)
                if violations:
                    print(f"âš ï¸ NGãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡ºãƒ»é™¤å»ã—ã¾ã—ãŸ: {violations}")
                    script_data = cleaned_script
            
            # APIä½¿ç”¨ãƒ­ã‚°ã‚’è¨˜éŒ²
            self.log_api_usage(
                request_type='integrated_script_generation',
                tokens_used=response.usage.total_tokens,
                cost_jpy=self.calculate_cost(response.usage.total_tokens)
            )
            
            return script_data
            
        except Exception as e:
            print(f"âŒ çµ±åˆå°æœ¬ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            raise e
    
    def check_and_clean_script(self, script_data, category_id):
        """ç”Ÿæˆã•ã‚ŒãŸå°æœ¬ã®NGãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯ãƒ»é™¤å»"""
        if not category_id:
            return script_data, []
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰NGãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT word, word_type FROM ng_words WHERE category_id = ?', (category_id,))
        ng_words = cursor.fetchall()
        conn.close()
        
        if not ng_words:
            return script_data, []
        
        violations = []
        cleaned_script = script_data.copy()
        
        # å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯ãƒ»ã‚¯ãƒªãƒ¼ãƒ³
        for field in ['title', 'hook', 'main_content', 'call_to_action', 'script_content']:
            if field in cleaned_script and cleaned_script[field]:
                original_text = cleaned_script[field]
                cleaned_text = original_text
                
                for word, word_type in ng_words:
                    if word_type == 'exact':
                        if word in cleaned_text:
                            violations.append(word)
                            cleaned_text = cleaned_text.replace(word, '[è¦åˆ¶å¯¾è±¡]')
                    elif word_type == 'partial':
                        if word.lower() in cleaned_text.lower():
                            violations.append(word)
                            # å¤§æ–‡å­—å°æ–‡å­—ã‚’è€ƒæ…®ã—ãŸç½®æ›
                            import re
                            cleaned_text = re.sub(re.escape(word), '[è¦åˆ¶å¯¾è±¡]', cleaned_text, flags=re.IGNORECASE)
                    elif word_type == 'regex':
                        import re
                        if re.search(word, cleaned_text):
                            violations.append(word)
                            cleaned_text = re.sub(word, '[è¦åˆ¶å¯¾è±¡]', cleaned_text)
                
                cleaned_script[field] = cleaned_text
        
        return cleaned_script, violations
    
    def calculate_cost(self, tokens):
        """ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‹ã‚‰è²»ç”¨ã‚’è¨ˆç®—ï¼ˆGPT-4o-miniï¼‰"""
        # GPT-4o-miniã®æ–™é‡‘: å…¥åŠ› $0.00015/1K tokens, å‡ºåŠ› $0.0006/1K tokens
        # ç°¡å˜ã®ãŸã‚å¹³å‡ã¨ã—ã¦ $0.0003/1K tokens = 0.045å††/1K tokensï¼ˆ150å††/ãƒ‰ãƒ«æ›ç®—ï¼‰
        cost_per_1k_tokens = 0.045
        return (tokens / 1000) * cost_per_1k_tokens
    
    def log_api_usage(self, request_type, tokens_used, cost_jpy):
        """APIä½¿ç”¨ãƒ­ã‚°ã‚’è¨˜éŒ²"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO api_usage_log (date, request_type, tokens_used, cost_jpy, created_at)
                VALUES (DATE('now'), ?, ?, ?, DATETIME('now'))
            ''', (request_type, tokens_used, cost_jpy))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            print(f"âŒ APIä½¿ç”¨ãƒ­ã‚°ã®è¨˜éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    
    def get_daily_usage(self):
        """å½“æ—¥ã®APIä½¿ç”¨é‡ã‚’å–å¾—"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT COUNT(*) as request_count, 
                       SUM(tokens_used) as total_tokens,
                       SUM(cost_jpy) as total_cost
                FROM api_usage_log 
                WHERE date = DATE('now')
            ''')
            
            result = cursor.fetchone()
            conn.close()
            
            return {
                'request_count': result[0] or 0,
                'total_tokens': result[1] or 0,
                'total_cost': result[2] or 0.0
            }
            
        except Exception as e:
            print(f"âŒ ä½¿ç”¨é‡ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return {'request_count': 0, 'total_tokens': 0, 'total_cost': 0.0}
    
    def check_daily_limit(self):
        """æ—¥æ¬¡åˆ¶é™ã‚’ãƒã‚§ãƒƒã‚¯"""
        usage = self.get_daily_usage()
        
        # æ—¥æ¬¡åˆ¶é™ã®è¨­å®š
        daily_request_limit = 100
        daily_cost_limit = 500.0  # 500å††
        
        if usage['request_count'] >= daily_request_limit:
            return False, f"æ—¥æ¬¡ãƒªã‚¯ã‚¨ã‚¹ãƒˆåˆ¶é™({daily_request_limit}å›)ã«é”ã—ã¾ã—ãŸ"
        
        if usage['total_cost'] >= daily_cost_limit:
            return False, f"æ—¥æ¬¡ã‚³ã‚¹ãƒˆåˆ¶é™(Â¥{daily_cost_limit})ã«é”ã—ã¾ã—ãŸ"
        
        return True, "åˆ¶é™å†…ã§ã™"
    
    def analyze_generated_script(self, script_data):
        """ç”Ÿæˆã•ã‚ŒãŸå°æœ¬ã®å“è³ªã‚’åˆ†æ"""
        analysis = {
            'has_numbers': False,
            'has_urgency': False,
            'has_authority': False,
            'hook_strength': 0,
            'cta_strength': 0,
            'overall_score': 0
        }
        
        script_text = f"{script_data.get('hook', '')} {script_data.get('main_content', '')} {script_data.get('call_to_action', '')}"
        
        # æ•°å€¤ã®æœ‰ç„¡
        if re.search(r'\d+[,\d]*[å††ï¼…%ä¸‡å„„åƒç™¾å]', script_text):
            analysis['has_numbers'] = True
        
        # ç·Šæ€¥æ€§ã®æœ‰ç„¡
        urgency_words = ['ä»Šãªã‚‰', 'é™å®š', 'ä»Šã ã‘', 'ä»Šã™ã', 'æœŸé–“é™å®š']
        if any(word in script_text for word in urgency_words):
            analysis['has_urgency'] = True
        
        # æ¨©å¨æ€§ã®æœ‰ç„¡
        authority_words = ['ãƒ—ãƒ­ãƒ‡ãƒ¥ãƒ¼ã‚¹', 'èªå®š', 'ç ”ç©¶', 'å°‚é–€å®¶', 'åŠ¹æœ']
        if any(word in script_text for word in authority_words):
            analysis['has_authority'] = True
        
        # ãƒ•ãƒƒã‚¯å¼·åº¦ï¼ˆç°¡å˜ãªè©•ä¾¡ï¼‰
        hook = script_data.get('hook', '')
        if hook:
            hook_score = 0
            if re.match(r'^\d+', hook):  # æ•°å­—ã§å§‹ã¾ã‚‹
                hook_score += 2
            if 'ï¼Ÿ' in hook or '?' in hook:  # ç–‘å•æ–‡
                hook_score += 1
            if 'ï¼' in hook or '!' in hook:  # æ„Ÿå˜†ç¬¦
                hook_score += 1
            analysis['hook_strength'] = hook_score
        
        # CTAå¼·åº¦
        cta = script_data.get('call_to_action', '')
        if cta:
            cta_score = 0
            if 'ä»Šã™ã' in cta:
                cta_score += 2
            if 'ç„¡æ–™' in cta:
                cta_score += 1
            if 'ãƒã‚§ãƒƒã‚¯' in cta:
                cta_score += 1
            analysis['cta_strength'] = cta_score
        
        # ç·åˆã‚¹ã‚³ã‚¢
        overall_score = 0
        if analysis['has_numbers']:
            overall_score += 2
        if analysis['has_urgency']:
            overall_score += 2
        if analysis['has_authority']:
            overall_score += 2
        overall_score += analysis['hook_strength']
        overall_score += analysis['cta_strength']
        
        analysis['overall_score'] = overall_score
        
        return analysis

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
if __name__ == "__main__":
    print("=== çµ±åˆç‰ˆOpenAIçµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
    
    # .envãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    if os.path.exists('.env'):
        print("âœ… .envãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
    else:
        print("âŒ .envãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        exit(1)
    
    # OpenAIçµ±åˆã®åˆæœŸåŒ–
    openai_service = OpenAIIntegration()
    
    if openai_service.client:
        print("âœ… OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒæ­£å¸¸ã«åˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ç¢ºèª
        try:
            conn = sqlite3.connect('ad_script_database.db')
            cursor = conn.cursor()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            tables = cursor.fetchall()
            conn.close()
            print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒæ­£å¸¸ã«ç¢ºèªã•ã‚Œã¾ã—ãŸ")
            
            # ç°¡å˜ãªãƒ†ã‚¹ãƒˆç”Ÿæˆ
            print("\n=== çµ±åˆç‰ˆå°æœ¬ç”Ÿæˆãƒ†ã‚¹ãƒˆ ===")
            test_script = openai_service.generate_script(
                category="å¥åº·ã‚µãƒ—ãƒªãƒ¡ãƒ³ãƒˆ",
                target_audience="30-50ä»£ç”·æ€§",
                platform="TikTok",
                script_length="30ç§’",
                reference_scripts=None,
                category_id=1
            )
            
            print("âœ… çµ±åˆç‰ˆå°æœ¬ç”ŸæˆæˆåŠŸï¼")
            print(f"ã‚¿ã‚¤ãƒˆãƒ«: {test_script['title']}")
            print(f"ãƒ•ãƒƒã‚¯: {test_script['hook']}")
            print(f"ãƒ¡ã‚¤ãƒ³: {test_script['main_content'][:100]}...")
            print(f"CTA: {test_script['call_to_action']}")
            
            # å°æœ¬å“è³ªåˆ†æãƒ†ã‚¹ãƒˆ
            print("\n=== å°æœ¬å“è³ªåˆ†æãƒ†ã‚¹ãƒˆ ===")
            analysis = openai_service.analyze_generated_script(test_script)
            print(f"æ•°å€¤å«æœ‰: {analysis['has_numbers']}")
            print(f"ç·Šæ€¥æ€§å«æœ‰: {analysis['has_urgency']}")
            print(f"æ¨©å¨æ€§å«æœ‰: {analysis['has_authority']}")
            print(f"ãƒ•ãƒƒã‚¯å¼·åº¦: {analysis['hook_strength']}")
            print(f"CTAå¼·åº¦: {analysis['cta_strength']}")
            print(f"ç·åˆã‚¹ã‚³ã‚¢: {analysis['overall_score']}")
            
            # NGãƒ¯ãƒ¼ãƒ‰æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
            print("\n=== NGãƒ¯ãƒ¼ãƒ‰æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ ===")
            test_script_with_ng = {
                "title": "çµ¶å¯¾ã«åŠ¹æœãŒã‚ã‚‹å•†å“",
                "hook": "ã“ã®å•†å“ã¯çµ¶å¯¾ã«åŠ¹æœãŒã‚ã‚Šã¾ã™",
                "main_content": "100%ã®åŠ¹æœã‚’ä¿è¨¼ã—ã¾ã™",
                "call_to_action": "ä»Šã™ãè³¼å…¥ã—ã¦ãã ã•ã„",
                "script_content": "çµ¶å¯¾ã«åŠ¹æœãŒã‚ã‚‹å•†å“ã§ã™"
            }
            
            cleaned_script, violations = openai_service.check_and_clean_script(test_script_with_ng, 1)
            if violations:
                print(f"âœ… NGãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºãƒ»é™¤å»æˆåŠŸ: {violations}")
                print(f"ã‚¯ãƒªãƒ¼ãƒ³å¾Œã‚¿ã‚¤ãƒˆãƒ«: {cleaned_script['title']}")
            else:
                print("â„¹ï¸ NGãƒ¯ãƒ¼ãƒ‰ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼ˆNGãƒ¯ãƒ¼ãƒ‰ãŒæœªç™»éŒ²ã®å ´åˆï¼‰")
            
        except Exception as e:
            print(f"âŒ ãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    else:
        print("âŒ OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    print("\nâœ… çµ±åˆç‰ˆOpenAIçµ±åˆã®ãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
